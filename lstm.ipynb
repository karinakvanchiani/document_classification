{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TEXT_FILE_PATH = 'C:/Users/kvanc/session/document_classification/datasets/text.txt'\n",
    "\n",
    "with open(TRAIN_TEXT_FILE_PATH, encoding='utf-8') as text_file:\n",
    "    text_sample = text_file.readlines()\n",
    "    \n",
    "\n",
    "text_sample = ' '.join(text_sample)\n",
    "\n",
    "def text_to_seq(text_sample):\n",
    "    char_counts = Counter(text_sample)\n",
    "    char_counts = sorted(char_counts.items(), key = lambda x: x[1], reverse=True)\n",
    "\n",
    "    sorted_chars = [char for char, _ in char_counts]\n",
    "\n",
    "    char_to_idx = {char: index for index, char in enumerate(sorted_chars)}\n",
    "    idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "    sequence = np.array([char_to_idx[char] for char in text_sample])\n",
    "    \n",
    "    return sequence, char_to_idx, idx_to_char\n",
    "\n",
    "sequence, char_to_idx, idx_to_char = text_to_seq(text_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "def get_batch(sequence):\n",
    "    trains = []\n",
    "    targets = []\n",
    "    for _ in range(BATCH_SIZE):\n",
    "        batch_start = np.random.randint(0, len(sequence) - SEQ_LEN)\n",
    "        chunk = sequence[batch_start: batch_start + SEQ_LEN]\n",
    "        train = torch.LongTensor(chunk[:-1]).view(-1, 1)\n",
    "        target = torch.LongTensor(chunk[1:]).view(-1, 1)\n",
    "        trains.append(train)\n",
    "        targets.append(target)\n",
    "    return torch.stack(trains, dim=0), torch.stack(targets, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
    "    hidden = model.init_hidden()\n",
    "    idx_input = [char_to_idx[char] for char in start_text]\n",
    "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
    "    predicted_text = start_text\n",
    "    \n",
    "    _, hidden = model(train, hidden)\n",
    "        \n",
    "    inp = train[-1].view(-1, 1, 1)\n",
    "    \n",
    "    for i in range(prediction_len):\n",
    "        output, hidden = model(inp.to(device), hidden)\n",
    "        output_logits = output.cpu().data.view(-1)\n",
    "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
    "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
    "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
    "        predicted_char = idx_to_char[top_index]\n",
    "        predicted_text += predicted_char\n",
    "    \n",
    "    return predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n",
    "        super(TextRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        x = self.encoder(x).squeeze(2)\n",
    "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
    "        out = self.dropout(out)\n",
    "        x = self.fc(out)\n",
    "        return x, (ht1, ct1)\n",
    "    \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
    "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.827471251487732\n",
      " обнеризни ито праризна на подно обноды вода порреробнасто обние подно прозние на подна на доберсе облато обно подна себет обнара обнарате подно обнарете на подна прода проды на постоды воды жизни на п\n",
      "Loss: 1.2079283499717712\n",
      " орбитального морохного ультрафии с орбитального излучения на Марсе име существовала на Марсе ослаб, хотя необерса и сегодня на Марсе изменя на Марсе изменя на Марсе ослаб, хотя недетельные признакичес\n",
      "Loss: 0.28650111734867095\n",
      " надежды все еще держатся, и многие думают, что жизнь, возможно, существовала на Марсе в прошлом.\n",
      " \n",
      " Поиски жизни на Марсе\n",
      " В последние годы орбитальный аппарат обнаружил метан в марсианская атмосфера \n",
      "Loss: 0.10993815556168557\n",
      " надежды для пессимистов жизни на других планетах.\n",
      " \n",
      " Во-первых, ученые пришли к выводу, что Марс, планета без жидкой воды, когда-то пережила близкий к глобальному потопу, все время отрицая, что такое \n",
      "Loss: 0.07372940815985203\n",
      " Марсе ослаб, хотя некоторые надежды все еще держатся, и многие думают, что жизнь, возможно, существовала на Марсе в прошлом. Возможно Красная планета когда-то имела гораздо более существенную атмосфер\n",
      "Loss: 0.05965599909424782\n",
      " Марсе слишком низкое для поддержания жидкой воды.\n",
      " \n",
      " Исследовавшие поверхность Марса с 1976 году марсоходы, содержали три очень надежных эксперимента по обнаружению признаков жизни. Два эксперимента н\n",
      "Loss: 0.053307507559657095\n",
      " Марс за марсианскими образцами грунта. Красная планета примерно наполовину размером с Землю, и он имеет, по крайней мере, тонкую атмосферу. Вода существует на Марсе, хотя, вероятно, не в изобилии в па\n",
      "Loss: 0.052560499906539916\n",
      " Марсе в прошлом.\n",
      " \n",
      " Поиски жизни на Марсе\n",
      " В последние годы орбитальный аппарат обнаружил метан в марсианской атмосфере. Метан – это газ, часто добываемый живыми существами, хотя он также может формир\n",
      "Loss: 0.04615899294614792\n",
      " Марсе слишком низкое для поддержания жидкой воды.\n",
      " \n",
      " Это имеет захватывающие надежды для пессимистов жизни на других планетах.\n",
      " \n",
      " Во-первых, ученые пришли к выводу, что Марс, планета без жидкой воды, \n",
      "Loss: 0.045529740527272225\n",
      " обнаружению признаков жизни. Два эксперимента не показали никаких признаков живых организмов, третий эксперимент имел слабые, но неоднозначные данные. Даже самые оптимистичные искатели внеземной жизни\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = TextRNN(input_size=len(idx_to_char), hidden_size=128, embedding_size=128, n_layers=2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    patience=5, \n",
    "    verbose=True, \n",
    "    factor=0.5\n",
    ")\n",
    "\n",
    "n_epochs = 500\n",
    "loss_avg = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train, target = get_batch(sequence)\n",
    "    train = train.permute(1, 0, 2).to(device)\n",
    "    target = target.permute(1, 0, 2).to(device)\n",
    "    hidden = model.init_hidden(BATCH_SIZE)\n",
    "\n",
    "    output, hidden = model(train, hidden)\n",
    "    loss = criterion(output.permute(1, 2, 0), target.squeeze(-1).permute(1, 0))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss_avg.append(loss.item())\n",
    "    if len(loss_avg) % 50 == 0:\n",
    "        mean_loss = np.mean(loss_avg)\n",
    "        print(f'Loss: {mean_loss}')\n",
    "        scheduler.step(mean_loss)\n",
    "        loss_avg = []\n",
    "        model.eval()\n",
    "        predicted_text = evaluate(model, char_to_idx, idx_to_char)\n",
    "        print(predicted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". обнаружению признаков жизни. Два эксперимента не показали никаких признаков живых организмов, третий эксперимент имел слабые, но неоднозначные данные. Даже самые оптимистичные искатели внеземной жизни согласны с тем, что эти незначительные положительные признаки, вероятно, были результатом неорганических химических реакций в почве. Помимо жуткого холода и редкости воды, сегодня на Марсе есть и другие препятствия для жизни. Например, тонкая марсианская атмосфера не обеспечивает защиту солнечного ультрафиолетового излучения, которое летально для живых существ.\n",
      " \n",
      " С этими проблемами интерес к жизни на Марсе ослаб, хотя некоторые надежды все еще держатся, и многие думают, что жизнь, возможно, существовала на Марсе в прошлом. Возможно Красная планета когда-то имела гораздо более существенную атмосферу, чем сейчас, атмосферу, которая обеспечивала достаточное давление и тепло для поддержания жидкой воды.\n",
      " \n",
      " Исследовавшие поверхность Марса с 1976 году марсоходы, содержали три очень надежных эк\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(evaluate(\n",
    "    model, \n",
    "    char_to_idx, \n",
    "    idx_to_char, \n",
    "    temp=0.3, \n",
    "    prediction_len=1000, \n",
    "    start_text='. '\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
